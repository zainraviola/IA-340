{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf92b1a-21f5-4050-a80d-6b7acd6bef60",
   "metadata": {},
   "source": [
    "# Analyze Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefcacfa-814a-460e-9d28-1ad683a684ab",
   "metadata": {},
   "source": [
    "Analyze the collected Twitter data with OpenAI and store the results in a MongoDB database. The analyses include:\n",
    "\n",
    "- Sentiment analysis\n",
    "- Language translation\n",
    "- Identify emotions\n",
    "- Extract entities\n",
    "- Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdff760-a533-4ebf-b873-0d8576729536",
   "metadata": {},
   "source": [
    "## Install Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b55ccf-2acb-433c-90d4-ae9bb4bc5522",
   "metadata": {},
   "source": [
    "- pymongo: manage the MongoDB database\n",
    "- openai: call the OpenAI APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f5cfe2-a541-41bf-803d-e597e343d02c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.15.4)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pymongo) (2.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68dc7477-3a4f-4518-9046-3ffd289227cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.8.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aed8ba-c4ac-4547-90a1-6d7bb9ba45d7",
   "metadata": {},
   "source": [
    "## Secret Manager Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac5f795d-e334-411b-b3f2-2fe9bed01a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8027b1d-9fda-4cb3-9eb7-72d737d8687a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Python Libraries and Credentials  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9693a5a-f992-45a0-9961-0f7b1e7d2f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "from pprint import pprint\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "\n",
    "mongodb_connect = get_secret('mongodb')['connection_string']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c43621-a23c-4cff-a92e-baf838b9cfe3",
   "metadata": {},
   "source": [
    "## Connect to the MongoDB cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a29b88d5-b53a-4267-b9d6-c5e1d313b81a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tweet.id_1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo_client = MongoClient(mongodb_connect)\n",
    "db = mongo_client.demo # use or create a database named demo\n",
    "tweet_collection = db.tweet_collection #use or create a collection named tweet_collection\n",
    "tweet_collection.create_index([(\"tweet.id\", pymongo.ASCENDING)],unique = True) # make sure the collected tweets are unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de89aa-b735-48da-8ce2-ecd861c2d729",
   "metadata": {},
   "source": [
    "## Extract Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc8921a-3df9-42dc-9507-6f6287089bd9",
   "metadata": {},
   "source": [
    "Filter the Tweets you are interested in. You can use MongoDB Compass to help you write the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4a47a1f-143f-41c5-87b3-9b2b520b9376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter={\n",
    "\n",
    "    \n",
    "}\n",
    "project={\n",
    "    'tweet.text': 1, \n",
    "    'tweet.id': 1\n",
    "}\n",
    "#rename the client to mongo_client\n",
    "result = mongo_client['demo']['tweet_collection'].find(\n",
    "  filter=filter,\n",
    "  projection=project\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43ed0e-f23a-4a7e-8dfc-88443b137bc1",
   "metadata": {},
   "source": [
    "Save the extracted Tweets into the ```tweet_data``` list. Remove URLs and new lines to save the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fef848c-0352-42cc-9bfa-462508601102",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tweet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30723/3719299771.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtext_without_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtweet_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'tweet_id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tweet_text'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtext_without_urls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tweet'"
     ]
    }
   ],
   "source": [
    "tweet_data = []\n",
    "url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "for tweet in result:\n",
    "    text_without_urls = re.sub(url_pattern, '', tweet['tweet']['text'])\n",
    "    tweet_data.append({'tweet_id':tweet['tweet']['id'],'tweet_text':text_without_urls.replace('\\n','')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2655f42e-81f6-428a-a79c-1e9c9be3aa3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets:  0\n"
     ]
    }
   ],
   "source": [
    "print('Number of tweets: ',len(tweet_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c288dace-226b-47f1-a153-60f6044e21d4",
   "metadata": {},
   "source": [
    "## Set up OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e425649-b944-476b-b051-10e386a37031",
   "metadata": {},
   "source": [
    "Load the OpenAI API key and set the API parameters.\n",
    "\n",
    "- Model type: usegpt-4o by default, and you choose any [availabel models](https://platform.openai.com/docs/models).\n",
    "- Token estimate: 100 tokens ~= 75 words in English. Total token usage = tokens in the prompt + tokens in the completion. You can get a more accurate estimate at [Tokenier](https://platform.openai.com/tokenizer).\n",
    "- Temperature: Lower temperatures produce more consistent outputs, while higher values generate more diverse and creative results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996910ad-0ac9-4e7f-b20a-1c45f0a3c57f",
   "metadata": {},
   "source": [
    "A help function, ```openai_help```, is created to pass the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c24a56f1-d729-4d61-9344-441b126a86b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "model=\"gpt-4o\"\n",
    "temperature=0\n",
    "\n",
    "def openai_help(prompt, model=model, temperature =temperature ):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5808bba1-785c-4ccf-abdd-170ea861280a",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f403a-716e-4c06-a8d1-6098dfe48e41",
   "metadata": {},
   "source": [
    "Analyze the sentiment of each tweet and save the result to the MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3c09ce2-c467-4782-892c-ed6d911612d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2721ae24bb46ada699ed4c22a55864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for tweet in tqdm(tweet_data):\n",
    "  \n",
    "    prompt = f\"\"\"\n",
    "    What is the sentiment of the following tweet, \n",
    "    tweet text: {tweet['tweet_text']}\n",
    "    return  the result with one word as Positive, Neutral,or Negative\n",
    " \n",
    "    \"\"\"\n",
    "#     print(prompt)\n",
    "    try:\n",
    "        sentiment_result =openai_help(prompt)\n",
    "    #     print(sentiment_result)\n",
    "\n",
    "        tweet_collection.update_one(\n",
    "            {'tweet.id':tweet['tweet_id']},\n",
    "            {\"$set\":{'tweet.sentiment':sentiment_result}}\n",
    "        )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f2c52-38a5-4ae2-b185-0a1f81763f50",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Language translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b69cff-e278-4613-a5c0-58aa042a9a87",
   "metadata": {},
   "source": [
    "Translate each tweet into a different language and save the result to the MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48a66b2d-2aa1-4074-bbdd-3f5483dcbcc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c9650f4b2340ab8ed051de9a36b681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for tweet in tqdm(tweet_data):\n",
    "  \n",
    "    prompt = f\"\"\"\n",
    "    Translate the following tweet into Chinese\n",
    "    tweet text: {tweet['tweet_text']}\n",
    " \n",
    "    \"\"\"\n",
    "#     print(prompt)\n",
    "    try:\n",
    "        translate_result =openai_help(prompt)\n",
    "#         print(translate_result)\n",
    "\n",
    "        tweet_collection.update_one(\n",
    "            {'tweet.id':tweet['tweet_id']},\n",
    "            {\"$set\":{'tweet.translate':translate_result}}\n",
    "        )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f49995-c37d-47da-94f9-6600b4af83c5",
   "metadata": {},
   "source": [
    "## Identify emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a76ee-a860-45bd-9b46-125313a53bfd",
   "metadata": {},
   "source": [
    "Identify whether a tweet expresses anger, and save the result to the MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf4d952c-e418-475c-8d66-a5aea631ce47",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccb8922cc0a447da96cdd4d2c9ff9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for tweet in tqdm(tweet_data):\n",
    "  \n",
    "    prompt = f\"\"\"\n",
    "    Detect the emotion in the following tweet, and extract whether the tweet expresses anger.\n",
    "    Provide the result as True, False, or Unknown. \n",
    "    Don't provide any reasoning or other output.\n",
    "    tweet text: {tweet['tweet_text']}\n",
    " \n",
    "    \"\"\"\n",
    "#     print(prompt)\n",
    "    try:\n",
    "        emotion_result =openai_help(prompt)\n",
    "        # print(emotion_result)\n",
    "\n",
    "        tweet_collection.update_one(\n",
    "                {'tweet.id':tweet['tweet_id']},\n",
    "                {\"$set\":{'tweet.anger':emotion_result}}\n",
    "            )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9297c56-9faf-4d5b-ac07-e1ad670ae78b",
   "metadata": {},
   "source": [
    "## Extract entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1f09e0-2ddd-4fe7-973a-c238067761c4",
   "metadata": {},
   "source": [
    "Extract person and organization names from each tweet and save the result to the MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "918a668f-3e48-40aa-a7fa-cd150254bd87",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2901595e1a484ff2bea05b9990033310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for tweet in tqdm(tweet_data):\n",
    "  \n",
    "    prompt = f\"\"\"\n",
    "    Identify persons or organizations from the following tweet,\n",
    "    tweet text: {tweet['tweet_text']},\n",
    "    format the response as a JSON object with Person and Organization as the keys, and extracted items in a list,\n",
    "    if no entities is not presented, use \"Unknown\" in the list.\n",
    "    Do not wrap the JSON codes in JSON markers\n",
    "   \n",
    "    \"\"\"\n",
    "#     print(prompt)\n",
    "    try:\n",
    "        extract_result =openai_help(prompt)\n",
    "#        print(extract_result)\n",
    "\n",
    "        tweet_collection.update_one(\n",
    "                {'tweet.id':tweet['tweet_id']},\n",
    "                {\"$set\":{'tweet.extracted_item':json.loads(extract_result)}}\n",
    "                )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb16b3-6186-4eed-b134-3f585f099981",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ebf1b1-10f2-48e0-ade6-a3bf1d8437e6",
   "metadata": {},
   "source": [
    "Summarize the tweet texts with a specific focus and save the result to the MongoDB database. By default, 500 tweets are analyzed in each batch. You can change the batch size based on the model you use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac8549a0-886f-4f4b-8929-774d1435bdec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the batch size\n",
    "batch_size = 500\n",
    "\n",
    "start_index = 0\n",
    "\n",
    "\n",
    "while start_index < len(tweet_data):\n",
    "    batch = tweet_data[start_index:start_index + batch_size]\n",
    "\n",
    "    tweet_id_list =[]\n",
    "    tweet_text_summary =''\n",
    "    \n",
    "    for tweet in batch:\n",
    "        tweet_id_list.append(tweet['tweet_id'])\n",
    "        tweet_text_summary = tweet_text_summary+'.'+tweet['tweet_text']\n",
    "        \n",
    "    prompt = f\"\"\"\n",
    "    Summarize the following tweets in at most 50 words, \n",
    "    tweet text: {tweet_text_summary,}\n",
    " \n",
    "    \"\"\"\n",
    "#     print(prompt)\n",
    "    try:\n",
    "        summary_result =openai_help(prompt)\n",
    "\n",
    "        tweet_summary = db.tweet_summary \n",
    "        tweet_summary.insert_one({'id_list':tweet_id_list,\n",
    "                            'tweet_text_summary':summary_result})\n",
    "        print(summary_result,'\\n')\n",
    "    except:\n",
    "        pass\n",
    "    start_index += batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e84860-fd13-4751-a272-dadb5a327fa5",
   "metadata": {},
   "source": [
    "## Close Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a69c341-fb79-45bb-bbd0-0864df2e3cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mongo_client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
