{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c45825e-0783-473b-adac-45bd7953b97e",
   "metadata": {},
   "source": [
    "# Exploring Twitter Data with Vector Databases and RAG Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6c716f-6b4c-46e9-b6ad-10efc429fb22",
   "metadata": {},
   "source": [
    "This tutorial introduces the creation of a vector database and the use of a retrieval-augmented generation (RAG) system to explore Twitter data interactively. \n",
    "\n",
    "Please check [LBSocial](www.lbsocial.net)  on how to collect Twitter data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00579d-601d-4cd2-883e-8716fa956f6d",
   "metadata": {},
   "source": [
    "## Set up a Database and API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f19853-7955-4634-b649-fb870e6cbde6",
   "metadata": {},
   "source": [
    "Create a [MongoDB](www.mongodb.com) cluster and store the connection string in a safe place, such as AWS Secrets Manager. \n",
    "- key name: `connection_string`\n",
    "- key value: <`the connection string`>, you need to type the password\n",
    "- secret name: `mongodb`\n",
    "\n",
    "\n",
    "You also need to purchase and your [oepnai](https://openai.com/) api key in AWS Secrets Manager:\n",
    "- key name: `api_key`\n",
    "- key value: <`your openai api key`>\n",
    "- secret name: `openai`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741094a9-2341-428c-8890-6d25a7b5a57f",
   "metadata": {},
   "source": [
    "## Install Python Libraries\n",
    "\n",
    "- pymongo: manage the MongoDB database\n",
    "- openai: create embeddings and resonpses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0541cd55-a63a-4ea7-b109-64e638f68058",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d81b42-f298-4dc9-a774-323ce4a7abd9",
   "metadata": {},
   "source": [
    "## Secrets Manager Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193ba904-b9ee-4079-87bf-7b9e079afddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f82551-7cae-45a8-901f-ded99fcb1c5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Python Libraries and Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a90eb91-dbed-45c8-954f-ec6a59066975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from openai import OpenAI\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "\n",
    "mongodb_connect = get_secret('mongodb')['connection_string']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f4198-edb0-4004-9ccb-c4f5cc083f33",
   "metadata": {},
   "source": [
    "## Connect to the MongoDB cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c730e7-cd46-4137-819a-c0de76c2f0ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mongo_client = MongoClient(mongodb_connect)\n",
    "db = mongo_client.demo # use or create a database named demo\n",
    "tweet_collection = db.tweet_collection #use or create a collection named tweet_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19a687-2bd7-4650-a4bc-c2f22b29b314",
   "metadata": {},
   "source": [
    "## Utility Funcitons\n",
    "\n",
    "- the `clean_tweet` function removes URLs in tweets\n",
    "- the `get_embedding` function use openai to create tweet embeddings\n",
    "- the `vector_search` function return relevent tweets based on a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83bdc6aa-c9b9-4fa8-b076-e901e10ef7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    return re.sub(url_pattern, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a14ad6e-f65b-4214-a935-acc6162116cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_model= 'text-embedding-3-small'\n",
    "\n",
    "def get_embedding(text):\n",
    "\n",
    "    try:\n",
    "        embedding = client.embeddings.create(input=text, model=embedding_model).data[0].embedding\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_embedding: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4584482b-2cc8-47e4-8d42-d303975b4353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vector_search(query):\n",
    "\n",
    "    query_embedding = get_embedding(query)\n",
    "    if query_embedding is None:\n",
    "        return \"Invalid query or embedding generation failed.\"\n",
    "    # Define the vector search pipeline\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": \"tweet_vector\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"path\": \"tweet.embedding\",\n",
    "                \"numCandidates\": 1000,  # Number of candidate matches to consider\n",
    "                \"limit\": 10  # Return top 10 matches\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,  # Exclude the _id field\n",
    "                \"tweet.text\": 1 # return tweet text\n",
    "\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = tweet_collection.aggregate(pipeline)\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cb5866-c09b-4779-b139-80d041a693f8",
   "metadata": {},
   "source": [
    "## Tweets Embedding \n",
    "\n",
    "For more about text embeddings please read [Introducing text and code embeddings](https://openai.com/index/introducing-text-and-code-embeddings/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f08f57-06f8-4e9c-9388-75da5d0ea6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaec82728e1e4dfe83146c48e4b8e30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tweets = tweet_collection.find()\n",
    "\n",
    "for tweet in tqdm(list(tweets)):\n",
    "    try:\n",
    "        tweet_embedding = get_embedding(clean_tweet(tweet['tweet']['text']))\n",
    "    #     print(tweet_embedding)\n",
    "\n",
    "        tweet_collection.update_one(\n",
    "            {'tweet.id':tweet['tweet']['id']},\n",
    "            {\"$set\":{'tweet.embedding':tweet_embedding}}\n",
    "        )\n",
    "    except:\n",
    "        print(f\"\"\"error in embedding tweet {tweet['tweet']['id']}\"\"\")\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741b8a55-60c7-4c9f-a64f-3861421e281c",
   "metadata": {},
   "source": [
    "## Create a Vector Index\n",
    "\n",
    "For more about the MognoDB Vector database, please read [What are Vector Databases?](https://www.mongodb.com/resources/basics/databases/vector-databases)\n",
    "This code creates a vector index following the [MongoDB official document](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-type/#std-label-avs-types-vector-search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86ec0671-54a7-4c21-bb49-8019bc7437c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New search index named tweet_vector is building.\n",
      "Polling to check if the index is ready. This may take up to a minute.\n",
      "tweet_vector is ready for querying.\n"
     ]
    }
   ],
   "source": [
    "# Create your index model, then create the search index\n",
    "\n",
    "from pymongo.operations import SearchIndexModel\n",
    "import time\n",
    "\n",
    "search_index_model = SearchIndexModel(\n",
    "  definition={\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"tweet.embedding\",\n",
    "      \"numDimensions\": 1536,\n",
    "      \"similarity\": \"cosine\"\n",
    "    }\n",
    "  ]\n",
    "},\n",
    "  name=\"tweet_vector\",\n",
    "  type=\"vectorSearch\"\n",
    "\n",
    ")\n",
    "result = tweet_collection.create_search_index(model=search_index_model)\n",
    "print(\"New search index named \" + result + \" is building.\")\n",
    "# Wait for initial sync to complete\n",
    "print(\"Polling to check if the index is ready. This may take up to a minute.\")\n",
    "predicate=None\n",
    "\n",
    "if predicate is None:\n",
    "  predicate = lambda index: index.get(\"queryable\") is True\n",
    "\n",
    "while True:\n",
    "  indices = list(tweet_collection.list_search_indexes(result))\n",
    "  if len(indices) and predicate(indices[0]):\n",
    "\n",
    "    break\n",
    "  time.sleep(5)\n",
    "\n",
    "print(result + \" is ready for querying.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c54c039e-9f47-4a34-8dfe-5c13f8cc2b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @rachalixie: kaveh learning morse code so he can tap out compliments to alhaitham on their dinner table while they eat and he only realiâ€¦\n",
      "RT @mattvanswol: @libsoftiktok They are voting.\n",
      "They are getting free education.\n",
      "They are getting free healthcare.\n",
      "They are getting free foâ€¦\n",
      "RT @iLatif_: All work and no food makes jack a dull boy https://t.co/5L8PgCnCM0\n",
      "@azabu_food ç–‘æƒ‘ãŒäº‹å®Ÿã«ãªã£ãŸã‚„ã¤\n",
      "RT @sovpsop: twitter learns that avoidant restrictive food intake disorder makes you avoid and restrict your intake of food\n",
      "@WolfsTheName @WatcherGuru AI and humanoid robots will automate repetitive labor, exponentially increasing productivity and reducing costs for essentials like food, energy, and housing to near-zero. This abundance shifts human focus to creative, innovative endeavors that fulfill us more than drudgery.\n",
      "RT @Khris_mah: Prove of food ðŸ˜‹ https://t.co/LXJnI8jYDJ\n",
      "RT @charise_lee: They grow and pick our foodâ€¼ï¸\n",
      "Hard back breaking workâ€¼ï¸ https://t.co/y8ub9IP0dn\n",
      "@LifeBloodisLife //itâ€™s funny to imagine the. Citadel just callously giving the Judges poisonous food to â€œtest their faithâ€ and it just drives them crazy.\n",
      "@akgaece Look who like to watch his idol touhing his 2 inches ðŸ˜‚. And u want him to promote brand with high reputation in food industry, luxury brands and beauty brand https://t.co/YpJIcvEsdH\n"
     ]
    }
   ],
   "source": [
    "user_query = 'study ai'\n",
    "\n",
    "for tweet in vector_search(user_query):\n",
    "    print(tweet['tweet']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe41db-4fa6-4269-b32c-1acd5d8e0756",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation (RAG) \n",
    "\n",
    "For more about RAG, please read [Retrieval-Augmented Generation (RAG) with Atlas Vector Search](https://www.mongodb.com/docs/atlas/atlas-vector-search/rag/#std-label-avs-rag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "700df598-edc6-4df5-a451-af64200e60f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "delimiter = '###'\n",
    "chat_model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "chat_history = [{\"role\": \"system\", \"content\": \"\"\" you are a chatbot, answer user questions based on the returned tweets.\"\"\"}]\n",
    "\n",
    "def chatbot(prompt):\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    tweets = vector_search(prompt)\n",
    "    chat_history.append({\"role\": \"system\", \"content\": f\" here the returned tweets delimited by {delimiter}{tweets}{delimiter}\"})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=chat_model,  # Use the model you prefer\n",
    "        messages=chat_history\n",
    "    )\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76db5ca-abb0-4c64-a85c-0fabb74f55ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    reply = chatbot(user_input)\n",
    "    print(f\"Chatbot: {reply}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8285852d-2eff-4a06-9865-1e9b0c70da7d",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- *â€œIntroducing Text and Code Embeddings.â€* n.d. OpenAI. Accessed October 31, 2024. https://openai.com/index/introducing-text-and-code-embeddings/.\n",
    "- *â€œWhat Are Vector Databases?â€* n.d. MongoDB. Accessed October 31, 2024. https://www.mongodb.com/resources/basics/databases/vector-databases.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
